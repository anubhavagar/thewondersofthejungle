{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§∏ Gymnastics Skill Detection - YOLOv8 Training\n",
                "\n",
                "**This notebook trains a YOLOv8 object detection model for gymnastics skills and exports to TFLite for MediaPipe integration.**\n",
                "\n",
                "‚úÖ **No dependency errors**  \n",
                "‚úÖ **Faster training** (1-2 hours with GPU)  \n",
                "‚úÖ **Better accuracy** than MediaPipe Model Maker  \n",
                "‚úÖ **TFLite export** for MediaPipe compatibility  \n",
                "\n",
                "---\n",
                "\n",
                "## üìã Quick Start\n",
                "\n",
                "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
                "2. **Run all cells**: Runtime ‚Üí Run all\n",
                "3. **Upload dataset** when prompted (ZIP file of `skill_detect_dataset`)\n",
                "4. **Wait 1-2 hours** for training\n",
                "5. **Download model** at the end"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Install YOLOv8 (No Errors!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q ultralytics scikit-learn tqdm\n",
                "print(\"‚úÖ Installation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Import Libraries & Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import xml.etree.ElementTree as ET\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "from sklearn.model_selection import train_test_split\n",
                "import yaml\n",
                "from tqdm import tqdm\n",
                "from ultralytics import YOLO\n",
                "import torch\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully!\")\n",
                "print(f\"üéÆ GPU available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Upload Dataset\n",
                "\n",
                "**Upload your `skill_detect_dataset.zip` file**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import zipfile\n",
                "\n",
                "print(\"üì§ Upload your dataset ZIP file (skill_detect_dataset.zip)\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Extract ZIP\n",
                "for filename in uploaded.keys():\n",
                "    print(f\"\\nüì¶ Extracting {filename}...\")\n",
                "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "        zip_ref.extractall('/content')\n",
                "    print(f\"‚úÖ Extracted successfully!\")\n",
                "\n",
                "# Set paths\n",
                "RAW_DATA_DIR = Path('/content/skill_detect_dataset')\n",
                "OUTPUT_DIR = Path('/content/yolo_dataset')\n",
                "\n",
                "# Verify dataset (check train folder directly if nested)\n",
                "train_dir = RAW_DATA_DIR / 'train'\n",
                "if not train_dir.exists():\n",
                "    # Maybe the images are directly in RAW_DATA_DIR or images/labels are already split\n",
                "    image_files = list(RAW_DATA_DIR.glob('**/*.jpg'))\n",
                "else:\n",
                "    image_files = list(train_dir.glob('*.jpg'))\n",
                "\n",
                "print(f\"\\n‚úÖ Found {len(image_files)} sample images in dataset search path\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training parameters\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 16\n",
                "IMG_SIZE = 640\n",
                "\n",
                "# Data split (if not already split)\n",
                "TRAIN_SPLIT = 0.8\n",
                "VAL_SPLIT = 0.2\n",
                "\n",
                "# Classes (identified from dataset)\n",
                "CLASSES = [\n",
                "    \"BL\",\n",
                "    \"FL\",\n",
                "    \"HS\",\n",
                "    \"IN-IRON-C\",\n",
                "    \"IRON-C\",\n",
                "    \"L-CROSS\",\n",
                "    \"LS\",\n",
                "    \"M-UP\",\n",
                "    \"PN\",\n",
                "    \"VS\"\n",
                "]\n",
                "\n",
                "print(\"‚öôÔ∏è Configuration:\")\n",
                "print(f\"   Epochs: {EPOCHS}\")\n",
                "print(f\"   Batch size: {BATCH_SIZE}\")\n",
                "print(f\"   Image size: {IMG_SIZE}\")\n",
                "print(f\"   Classes: {len(CLASSES)}\")\n",
                "print(f\"   Classes: {', '.join(CLASSES)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Convert Pascal VOC ‚Üí YOLO Format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_pascal_voc(xml_file):\n",
                "    \"\"\"Parse Pascal VOC XML annotation.\"\"\"\n",
                "    tree = ET.parse(xml_file)\n",
                "    root = tree.getroot()\n",
                "    \n",
                "    size = root.find('size')\n",
                "    width = int(size.find('width').text)\n",
                "    height = int(size.find('height').text)\n",
                "    \n",
                "    objects = []\n",
                "    for obj in root.findall('object'):\n",
                "        name = obj.find('name').text\n",
                "        bbox = obj.find('bndbox')\n",
                "        \n",
                "        xmin = int(bbox.find('xmin').text)\n",
                "        ymin = int(bbox.find('ymin').text)\n",
                "        xmax = int(bbox.find('xmax').text)\n",
                "        ymax = int(bbox.find('ymax').text)\n",
                "        \n",
                "        objects.append({\n",
                "            'class': name,\n",
                "            'bbox': [xmin, ymin, xmax, ymax]\n",
                "        })\n",
                "    \n",
                "    return {'width': width, 'height': height, 'objects': objects}\n",
                "\n",
                "\n",
                "def convert_to_yolo_format(annotation, class_mapping):\n",
                "    \"\"\"Convert Pascal VOC bbox to YOLO format (normalized center x, y, width, height).\"\"\"\n",
                "    img_width = annotation['width']\n",
                "    img_height = annotation['height']\n",
                "    \n",
                "    yolo_annotations = []\n",
                "    \n",
                "    for obj in annotation['objects']:\n",
                "        class_name = obj['class']\n",
                "        if class_name not in class_mapping:\n",
                "            continue\n",
                "            \n",
                "        class_id = class_mapping[class_name]\n",
                "        xmin, ymin, xmax, ymax = obj['bbox']\n",
                "        \n",
                "        # Convert to YOLO format\n",
                "        x_center = ((xmin + xmax) / 2) / img_width\n",
                "        y_center = ((ymin + ymax) / 2) / img_height\n",
                "        width = (xmax - xmin) / img_width\n",
                "        height = (ymax - ymin) / img_height\n",
                "        \n",
                "        # Clamp to [0, 1]\n",
                "        x_center = max(0, min(1, x_center))\n",
                "        y_center = max(0, min(1, y_center))\n",
                "        width = max(0, min(1, width))\n",
                "        height = max(0, min(1, height))\n",
                "        \n",
                "        yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
                "    \n",
                "    return yolo_annotations\n",
                "\n",
                "print(\"‚úÖ Conversion functions defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Prepare YOLO Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"PREPARING YOLO DATASET\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Create output directories\n",
                "for split in ['train', 'val']:\n",
                "    (OUTPUT_DIR / split / 'images').mkdir(parents=True, exist_ok=True)\n",
                "    (OUTPUT_DIR / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Create class mapping\n",
                "class_mapping = {name: idx for idx, name in enumerate(CLASSES)}\n",
                "\n",
                "# Get all image files recursively\n",
                "image_files = list(RAW_DATA_DIR.glob(\"**/*.jpg\")) + list(RAW_DATA_DIR.glob(\"**/*.png\"))\n",
                "print(f\"\\nFound {len(image_files)} images total\")\n",
                "\n",
                "# Parse and filter valid annotations\n",
                "print(\"\\nParsing annotations...\")\n",
                "valid_data = []\n",
                "\n",
                "for img_file in tqdm(image_files):\n",
                "    xml_file = img_file.with_suffix('.xml')\n",
                "    if not xml_file.exists():\n",
                "        # Check if xml is in same folder even if extension mapping is weird\n",
                "        xml_file = Path(str(img_file).rsplit('.', 1)[0] + '.xml')\n",
                "        if not xml_file.exists(): continue\n",
                "    \n",
                "    try:\n",
                "        annotation = parse_pascal_voc(xml_file)\n",
                "        if annotation['objects']:\n",
                "            valid_data.append((img_file, annotation))\n",
                "    except Exception as e:\n",
                "        continue\n",
                "\n",
                "print(f\"Valid images with annotations: {len(valid_data)}\")\n",
                "\n",
                "if len(valid_data) == 0:\n",
                "    print(\"‚ùå ERROR: No valid images found with XML annotations.\")\n",
                "else:\n",
                "    # Split dataset\n",
                "    train_idx, val_idx = train_test_split(\n",
                "        range(len(valid_data)), \n",
                "        train_size=TRAIN_SPLIT, \n",
                "        random_state=42\n",
                "    )\n",
                "\n",
                "    splits = {'train': train_idx, 'val': val_idx}\n",
                "    print(f\"\\nTrain: {len(train_idx)} images\")\n",
                "    print(f\"Val: {len(val_idx)} images\")\n",
                "\n",
                "    # Process each split\n",
                "    for split_name, indices in splits.items():\n",
                "        print(f\"\\nProcessing {split_name} split...\")\n",
                "        for idx in tqdm(indices, desc=f\"Converting {split_name}\"):\n",
                "            img_file, annotation = valid_data[idx]\n",
                "            yolo_annotations = convert_to_yolo_format(annotation, class_mapping)\n",
                "            if not yolo_annotations: continue\n",
                "            \n",
                "            # Copy image and write label\n",
                "            shutil.copy(img_file, OUTPUT_DIR / split_name / 'images' / img_file.name)\n",
                "            dst_label = OUTPUT_DIR / split_name / 'labels' / img_file.with_suffix('.txt').name\n",
                "            with open(dst_label, 'w') as f:\n",
                "                f.write('\\n'.join(yolo_annotations))\n",
                "\n",
                "    # Create data.yaml\n",
                "    data_yaml = {\n",
                "        'path': str(OUTPUT_DIR.absolute()),\n",
                "        'train': 'train/images',\n",
                "        'val': 'val/images',\n",
                "        'nc': len(CLASSES),\n",
                "        'names': CLASSES\n",
                "    }\n",
                "    yaml_path = OUTPUT_DIR / 'data.yaml'\n",
                "    with open(yaml_path, 'w') as f:\n",
                "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
                "\n",
                "    print(f\"\\n‚úÖ Dataset preparation complete! Config saved to: {yaml_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Train YOLOv8 Model\n",
                "\n",
                "**This will take 1-2 hours with GPU**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"TRAINING YOLOV8 MODEL\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Initialize YOLOv8 medium model\n",
                "model = YOLO('yolov8m.pt')\n",
                "\n",
                "print(f\"\\nEpochs: {EPOCHS}\")\n",
                "print(f\"Batch size: {BATCH_SIZE}\")\n",
                "print(\"\\nStarting training...\\n\")\n",
                "\n",
                "# Train model\n",
                "results = model.train(\n",
                "    data=str(yaml_path),\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    patience=20,\n",
                "    save=True,\n",
                "    device=0, \n",
                "    project='/content/runs/detect',\n",
                "    name='skill_detector',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    optimizer='AdamW',\n",
                "    cos_lr=True\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"‚úÖ TRAINING COMPLETE!\")\n",
                "print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_model = YOLO('/content/runs/detect/skill_detector/weights/best.pt')\n",
                "\n",
                "# Evaluate\n",
                "metrics = best_model.val()\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"EVALUATION RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
                "print(f\"mAP50-95: {metrics.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9Ô∏è‚É£ Export to TFLite (for MediaPipe)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"EXPORTING TO TFLITE\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "tflite_path = best_model.export(format='tflite', imgsz=IMG_SIZE, optimize=True)\n",
                "\n",
                "print(f\"\\n‚úÖ Model exported to TFLite!\")\n",
                "print(f\"   Path: {tflite_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîü Download Trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# Save metadata\n",
                "metadata = {\n",
                "    'model': 'YOLOv8m-Skill',\n",
                "    'epochs': EPOCHS,\n",
                "    'classes': CLASSES,\n",
                "    'trained_on': datetime.now().isoformat(),\n",
                "    'map50': float(metrics.box.map50)\n",
                "}\n",
                "with open('/content/runs/detect/skill_detector/metadata.json', 'w') as f:\n",
                "    json.dump(metadata, f, indent=2)\n",
                "\n",
                "print(\"üì• Downloading files...\\n\")\n",
                "files.download('/content/runs/detect/skill_detector/weights/best.pt')\n",
                "files.download(tflite_path)\n",
                "files.download('/content/runs/detect/skill_detector/metadata.json')\n",
                "\n",
                "print(\"\\nüéâ Training complete! Your model is ready to use.\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}